{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cbae7e0",
   "metadata": {},
   "source": [
    "# ................................................به نام حضرت دوست  .................................................... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e0dd24",
   "metadata": {},
   "source": [
    "در این گزارش که همراه کد هست قرار است به وسیله مدل عصبی \n",
    "\n",
    "fully connected\n",
    "\n",
    "داده های ژنوم را دسته‌بندی کنیم  و به ۶ کلاس مرتبط داده شده نسبت دهیم\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d13483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM ,Bidirectional ,Dense,Activation ,Input\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from typing import List\n",
    "from typing import List\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4d9fbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/hoseinlook/Projects/uni/GLOBAL_UNI_VENV/lib/python3.8/site-packages (4.2.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/hoseinlook/Projects/uni/GLOBAL_UNI_VENV/lib/python3.8/site-packages (from gensim) (1.8.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/hoseinlook/Projects/uni/GLOBAL_UNI_VENV/lib/python3.8/site-packages (from gensim) (6.0.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/hoseinlook/Projects/uni/GLOBAL_UNI_VENV/lib/python3.8/site-packages (from gensim) (1.22.3)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d7f87c",
   "metadata": {},
   "source": [
    "در سلول زیر تابعی نوشته شده است که از یک استرینگ زیرجمله های \n",
    "\n",
    "k-mer\n",
    "\n",
    "را برمیگرداند که در واقع از این ها به عنوان کلمات در این دنباله هایی که داریم میتوانیم در نظر بگیریم\n",
    "طول این کلمات را در ادامه ۱۰ داده ایم در واقع داریم کلمات ۱۰ کارکتری را از دنباله استرینگی استخراج میکنیم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d9df77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_kmers(sequence:str, k:int)->List[str]:\n",
    "    \"\"\"\n",
    "        inputs:\n",
    "                sequence: a sting that represent a DNA\n",
    "                k: parameter to produce k-mer list\n",
    "        return: list of kmers\n",
    "    \"\"\"\n",
    "    kmers = []\n",
    "    n_kmers = len(sequence) - k + 1\n",
    "\n",
    "    for i in range(n_kmers):\n",
    "        kmer = sequence[i:i + k]\n",
    "        kmers.append(kmer)\n",
    "\n",
    "    return kmers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c934b49",
   "metadata": {},
   "source": [
    "##  خواندن داده آموزش\n",
    "به وسیله پکیج پانداز از فایل اکسل داده ها را میخوانیم سپس یک ستون به این داده ها که نماینده طول هر توالی هست را در میسازیم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8e78f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Class5</td>\n",
       "      <td>TACCACCTACGCTGACAATGGATGTTATTGTACCCGATTCGAATTA...</td>\n",
       "      <td>10735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Class5</td>\n",
       "      <td>TGTTTATGTATCCGCCCATAAATAGCTTAGCGTTGACTACCGCTTG...</td>\n",
       "      <td>10737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Class3</td>\n",
       "      <td>TCAATATAGGCCACGGGCAACCCGTTGATATTTTGTGTGACGGTTG...</td>\n",
       "      <td>29409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Class6</td>\n",
       "      <td>TAGTTTTAGTAACGTTCCTCTCCGTTCTCAATTTATTCTTTTATTG...</td>\n",
       "      <td>2341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Class2</td>\n",
       "      <td>TCGCGTGCCGGGGCGACCGCGCCAGTATTGCCCATCCCCTTGATTG...</td>\n",
       "      <td>30096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>Class5</td>\n",
       "      <td>TACCACCTACGCTGACAATGGATGTTATTGTACCCGTTTCGAATTA...</td>\n",
       "      <td>10735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>Class6</td>\n",
       "      <td>TAGTTTTAGTAAGTTTGGTCCCATTCAATCACGTTCGGATGCGCTG...</td>\n",
       "      <td>2341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>Class1</td>\n",
       "      <td>GCTGGGTAATTTTAGGTTGGTTGGCGATCGCGCCACTATCGCACCG...</td>\n",
       "      <td>29350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>Class5</td>\n",
       "      <td>TACCACCTACGCTGACAATGGATGTTATTGTACCCGATTCGAATTA...</td>\n",
       "      <td>10735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>Class3</td>\n",
       "      <td>TATCGCACCGCGCTTTGATTGCCCTTTTCGCACACAAGCACGTGCG...</td>\n",
       "      <td>29782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1320 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Type                                           Sequence    len\n",
       "0     Class5  TACCACCTACGCTGACAATGGATGTTATTGTACCCGATTCGAATTA...  10735\n",
       "1     Class5  TGTTTATGTATCCGCCCATAAATAGCTTAGCGTTGACTACCGCTTG...  10737\n",
       "2     Class3  TCAATATAGGCCACGGGCAACCCGTTGATATTTTGTGTGACGGTTG...  29409\n",
       "3     Class6  TAGTTTTAGTAACGTTCCTCTCCGTTCTCAATTTATTCTTTTATTG...   2341\n",
       "4     Class2  TCGCGTGCCGGGGCGACCGCGCCAGTATTGCCCATCCCCTTGATTG...  30096\n",
       "...      ...                                                ...    ...\n",
       "1315  Class5  TACCACCTACGCTGACAATGGATGTTATTGTACCCGTTTCGAATTA...  10735\n",
       "1316  Class6  TAGTTTTAGTAAGTTTGGTCCCATTCAATCACGTTCGGATGCGCTG...   2341\n",
       "1317  Class1  GCTGGGTAATTTTAGGTTGGTTGGCGATCGCGCCACTATCGCACCG...  29350\n",
       "1318  Class5  TACCACCTACGCTGACAATGGATGTTATTGTACCCGATTCGAATTA...  10735\n",
       "1319  Class3  TATCGCACCGCGCTTTGATTGCCCTTTTCGCACACAAGCACGTGCG...  29782\n",
       "\n",
       "[1320 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/training_set.csv\")\n",
    "df[\"len\"] =df[\"Sequence\"].apply(lambda x:len(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86038cf4",
   "metadata": {},
   "source": [
    "در ادامه میبینیم که به طور میانگین طول توالی های ما ۲۰هزار است  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "246b4a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20146.206818181818"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"len\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a685327",
   "metadata": {},
   "source": [
    "در این قسمت از تابع بالا استفاده میکنیم و به ازای هر توالی لیست \n",
    "\n",
    "k-mers\n",
    "\n",
    "آن را اضافه میکنیم\n",
    "تا همانطور که در ادامه توضیح داده خواهد شد از آن اسنفاده کنیم\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0efca844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>len</th>\n",
       "      <th>k-mers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Class5</td>\n",
       "      <td>TACCACCTACGCTGACAATGGATGTTATTGTACCCGATTCGAATTA...</td>\n",
       "      <td>10735</td>\n",
       "      <td>[TACCA, ACCAC, CCACC, CACCT, ACCTA, CCTAC, CTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Class5</td>\n",
       "      <td>TGTTTATGTATCCGCCCATAAATAGCTTAGCGTTGACTACCGCTTG...</td>\n",
       "      <td>10737</td>\n",
       "      <td>[TGTTT, GTTTA, TTTAT, TTATG, TATGT, ATGTA, TGT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Class3</td>\n",
       "      <td>TCAATATAGGCCACGGGCAACCCGTTGATATTTTGTGTGACGGTTG...</td>\n",
       "      <td>29409</td>\n",
       "      <td>[TCAAT, CAATA, AATAT, ATATA, TATAG, ATAGG, TAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Class6</td>\n",
       "      <td>TAGTTTTAGTAACGTTCCTCTCCGTTCTCAATTTATTCTTTTATTG...</td>\n",
       "      <td>2341</td>\n",
       "      <td>[TAGTT, AGTTT, GTTTT, TTTTA, TTTAG, TTAGT, TAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Class2</td>\n",
       "      <td>TCGCGTGCCGGGGCGACCGCGCCAGTATTGCCCATCCCCTTGATTG...</td>\n",
       "      <td>30096</td>\n",
       "      <td>[TCGCG, CGCGT, GCGTG, CGTGC, GTGCC, TGCCG, GCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>Class5</td>\n",
       "      <td>TACCACCTACGCTGACAATGGATGTTATTGTACCCGTTTCGAATTA...</td>\n",
       "      <td>10735</td>\n",
       "      <td>[TACCA, ACCAC, CCACC, CACCT, ACCTA, CCTAC, CTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>Class6</td>\n",
       "      <td>TAGTTTTAGTAAGTTTGGTCCCATTCAATCACGTTCGGATGCGCTG...</td>\n",
       "      <td>2341</td>\n",
       "      <td>[TAGTT, AGTTT, GTTTT, TTTTA, TTTAG, TTAGT, TAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>Class1</td>\n",
       "      <td>GCTGGGTAATTTTAGGTTGGTTGGCGATCGCGCCACTATCGCACCG...</td>\n",
       "      <td>29350</td>\n",
       "      <td>[GCTGG, CTGGG, TGGGT, GGGTA, GGTAA, GTAAT, TAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>Class5</td>\n",
       "      <td>TACCACCTACGCTGACAATGGATGTTATTGTACCCGATTCGAATTA...</td>\n",
       "      <td>10735</td>\n",
       "      <td>[TACCA, ACCAC, CCACC, CACCT, ACCTA, CCTAC, CTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>Class3</td>\n",
       "      <td>TATCGCACCGCGCTTTGATTGCCCTTTTCGCACACAAGCACGTGCG...</td>\n",
       "      <td>29782</td>\n",
       "      <td>[TATCG, ATCGC, TCGCA, CGCAC, GCACC, CACCG, ACC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1320 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Type                                           Sequence    len  \\\n",
       "0     Class5  TACCACCTACGCTGACAATGGATGTTATTGTACCCGATTCGAATTA...  10735   \n",
       "1     Class5  TGTTTATGTATCCGCCCATAAATAGCTTAGCGTTGACTACCGCTTG...  10737   \n",
       "2     Class3  TCAATATAGGCCACGGGCAACCCGTTGATATTTTGTGTGACGGTTG...  29409   \n",
       "3     Class6  TAGTTTTAGTAACGTTCCTCTCCGTTCTCAATTTATTCTTTTATTG...   2341   \n",
       "4     Class2  TCGCGTGCCGGGGCGACCGCGCCAGTATTGCCCATCCCCTTGATTG...  30096   \n",
       "...      ...                                                ...    ...   \n",
       "1315  Class5  TACCACCTACGCTGACAATGGATGTTATTGTACCCGTTTCGAATTA...  10735   \n",
       "1316  Class6  TAGTTTTAGTAAGTTTGGTCCCATTCAATCACGTTCGGATGCGCTG...   2341   \n",
       "1317  Class1  GCTGGGTAATTTTAGGTTGGTTGGCGATCGCGCCACTATCGCACCG...  29350   \n",
       "1318  Class5  TACCACCTACGCTGACAATGGATGTTATTGTACCCGATTCGAATTA...  10735   \n",
       "1319  Class3  TATCGCACCGCGCTTTGATTGCCCTTTTCGCACACAAGCACGTGCG...  29782   \n",
       "\n",
       "                                                 k-mers  \n",
       "0     [TACCA, ACCAC, CCACC, CACCT, ACCTA, CCTAC, CTA...  \n",
       "1     [TGTTT, GTTTA, TTTAT, TTATG, TATGT, ATGTA, TGT...  \n",
       "2     [TCAAT, CAATA, AATAT, ATATA, TATAG, ATAGG, TAG...  \n",
       "3     [TAGTT, AGTTT, GTTTT, TTTTA, TTTAG, TTAGT, TAG...  \n",
       "4     [TCGCG, CGCGT, GCGTG, CGTGC, GTGCC, TGCCG, GCC...  \n",
       "...                                                 ...  \n",
       "1315  [TACCA, ACCAC, CCACC, CACCT, ACCTA, CCTAC, CTA...  \n",
       "1316  [TAGTT, AGTTT, GTTTT, TTTTA, TTTAG, TTAGT, TAG...  \n",
       "1317  [GCTGG, CTGGG, TGGGT, GGGTA, GGTAA, GTAAT, TAA...  \n",
       "1318  [TACCA, ACCAC, CCACC, CACCT, ACCTA, CCTAC, CTA...  \n",
       "1319  [TATCG, ATCGC, TCGCA, CGCAC, GCACC, CACCG, ACC...  \n",
       "\n",
       "[1320 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"k-mers\"] = df[\"Sequence\"].apply(lambda x :build_kmers(x,5))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ec40e7",
   "metadata": {},
   "source": [
    "# wordEmbedding\n",
    "دلیل استفاده ما از از این روش این است که ما به ازای هر کلمه یک بردار نماینده داشته باشیم  میتوانیم از این روش استفاده کنیم این روش با در نظر گرفتن پنجره هایی توالی کلمه ها را در نظر میگیرد و مفهوم این کلمات را در کل  میسنجد و بدین شکل  به ازای هر کلمه یک بردار در نظر میگیرد \n",
    "پس ما برای ساخت بردار نماینده هر یک از این کلمات نیاز داریم کل کلمات هر توالی را به عنوان  ورودی به کلاس زیر میدهیم \n",
    "سایز بردار را ۲۰۰ در نظر گرفته ایم\n",
    "این کلاس زیر مدل را میسازد و کش میکند که اگر دوباره ابجکتی از این کلاس ساخته شد از مدلی که قبلا ساخته شده استفاده کند\n",
    "اما متد زیر چه کاری انجام میدهد؟؟\n",
    "\n",
    "def embed()...\n",
    "\n",
    "در این متد ما لیستی از کلمات را میدهیم سپس این متد بردار هر یک را حساب کرده و به وسیله  روش\n",
    "\n",
    "TfIdf\n",
    "\n",
    "میانگین وزن دار میگیرد و یک بردار به عنوان بردار خروجی باز میگرداند\n",
    "## چرا از\n",
    "\n",
    "## TfIdf\n",
    "\n",
    "## ?استفاده میکنیم\n",
    "\n",
    "زیرا اگر میانگین معمولی از وکتور ها بگیریم به عنوان بردار نماینده توالی به خوبی تاثیر هر کلمه را در نظر نگرفته ایم\n",
    "برای مثال ما کلماتی که در همه توالی ها هستند و زیاد تکرار شده اند را به یک اندازه با بقیه میانگین گرفته ایم درصورتی که این توالی ها تاثیرر کمتری دارند زیرا همه جا هستند و در تصمیمگیری نهایی نقش کمتری دارند\n",
    "ولی در عوض وزن بیشتری به کلمات خاصتر و کم تکرارتر میدهیم\n",
    "\n",
    "## خروجی چیست؟\n",
    "پس با استفاده از دو روش بالا به  ازای هر کلمه برداری در نظر گرفتیم و  با گرفتن میانگین وزندار از این بردارها به ازای هر توالی داده شده ما یک بردار داریم که برای دسته بندی میتوانیم از آن استفاده کنیم\n",
    "حال در ادامه با استفاده از یک شبکه عصبی فولی کانکتد عملیات دسته بندی را انجام میدهیم\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47c5227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocToVec:\n",
    "    \n",
    "    def __init__(self, dataset:List[List] , vec_size = 200 , model_path = 'word2vec.model'):\n",
    "        \"\"\" Here we train our model and calculate tf-idf weights.\n",
    "\n",
    "        Args:\n",
    "            dataset (List[List]): Each item of this list is a list of tokens obtained from a document.\n",
    "            vec_size (int, optional): The size of the vector of each document. Defaults to 200.\n",
    "            model_path (str, optional): The path of pre-trained model. If there is no file in the specified \n",
    "            path, It trains a model with the dataset and saves the trained model. Defaults to 'word2vec.model'.\n",
    "        \"\"\"\n",
    "\n",
    "        self.vec_size = vec_size\n",
    "        \n",
    "        \n",
    "        \n",
    "        if not Path(model_path).is_file():\n",
    "            print('There is no pre-trained model. Going to train a model ...')\n",
    "            self.wordToVecModel = Word2Vec(\n",
    "                window = 10,\n",
    "                min_count=2,\n",
    "                workers=4,\n",
    "                vector_size = self.vec_size\n",
    "            )\n",
    "        \n",
    "            self.wordToVecModel.build_vocab(dataset)\n",
    "            \n",
    "            self.wordToVecModel.train(\n",
    "                dataset,\n",
    "                total_examples = self.wordToVecModel.corpus_count,\n",
    "                epochs = 20,\n",
    "            )\n",
    "            \n",
    "            self.wordToVecModel.save(model_path)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            print('Loading the model ...')\n",
    "            self.wordToVecModel = Word2Vec.load(model_path)\n",
    "        \n",
    "        con_train_data = [\" \".join(a) for a in dataset]\n",
    "        \n",
    "        self.tfIdfVectorizer=TfidfVectorizer(use_idf=True,\n",
    "                                        dtype = np.float64,\n",
    "                                        lowercase = False,\n",
    "                                        vocabulary = self.wordToVecModel.wv.index_to_key)\n",
    "        \n",
    "        self.tfIdfVectorizer.fit(con_train_data)\n",
    "        \n",
    "        dictionary = self.tfIdfVectorizer.get_feature_names()\n",
    "        self.dictToNum = {d:i for i,d in enumerate(dictionary)}\n",
    "        \n",
    "        \n",
    "    def embed(self, tokens:List):\n",
    "        \"\"\"Maps the input to a vector\n",
    "\n",
    "        Args:\n",
    "            tokens (List): List of tokens (don't forget to do preprocessing before \n",
    "            extracting tokens)\n",
    "\n",
    "        Returns:\n",
    "            Numpy Array: The vector of document\n",
    "        \"\"\"\n",
    "        \n",
    "        ti = self.tfIdfVectorizer.transform([\" \".join(tokens)])\n",
    "        \n",
    "        weights = np.squeeze(np.asarray(ti[0].T.todense()))\n",
    "        \n",
    "        vec = np.zeros((self.vec_size,))\n",
    "        sum_weights = 0\n",
    "        for k in set(tokens):\n",
    "            try:\n",
    "                word_vec = self.wordToVecModel.wv[k]\n",
    "                weight = weights[self.dictToNum[k]]\n",
    "                vec += word_vec * weight\n",
    "                sum_weights += weight\n",
    "            except KeyError:\n",
    "                pass\n",
    "        vec /= sum_weights\n",
    "        return vec\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02da02f1",
   "metadata": {},
   "source": [
    "حال در اینجا با استفاده از کلاس بالا به مدل امبدینگ خود را آموزش میدهیم و به یک ستون بردار به ازای هر توالی به دیتافریم خود اضافه میکنیم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5ba4519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoseinlook/Projects/uni/GLOBAL_UNI_VENV/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>len</th>\n",
       "      <th>k-mers</th>\n",
       "      <th>vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Class5</td>\n",
       "      <td>TACCACCTACGCTGACAATGGATGTTATTGTACCCGATTCGAATTA...</td>\n",
       "      <td>10735</td>\n",
       "      <td>[TACCA, ACCAC, CCACC, CACCT, ACCTA, CCTAC, CTA...</td>\n",
       "      <td>[0.14347037438654303, -0.09826718607041093, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Class5</td>\n",
       "      <td>TGTTTATGTATCCGCCCATAAATAGCTTAGCGTTGACTACCGCTTG...</td>\n",
       "      <td>10737</td>\n",
       "      <td>[TGTTT, GTTTA, TTTAT, TTATG, TATGT, ATGTA, TGT...</td>\n",
       "      <td>[0.15608204759534353, -0.10743600239410199, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Class3</td>\n",
       "      <td>TCAATATAGGCCACGGGCAACCCGTTGATATTTTGTGTGACGGTTG...</td>\n",
       "      <td>29409</td>\n",
       "      <td>[TCAAT, CAATA, AATAT, ATATA, TATAG, ATAGG, TAG...</td>\n",
       "      <td>[0.22348955288315472, -0.045752539952623295, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Class6</td>\n",
       "      <td>TAGTTTTAGTAACGTTCCTCTCCGTTCTCAATTTATTCTTTTATTG...</td>\n",
       "      <td>2341</td>\n",
       "      <td>[TAGTT, AGTTT, GTTTT, TTTTA, TTTAG, TTAGT, TAG...</td>\n",
       "      <td>[0.12861910830795006, -0.06960499866601161, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Class2</td>\n",
       "      <td>TCGCGTGCCGGGGCGACCGCGCCAGTATTGCCCATCCCCTTGATTG...</td>\n",
       "      <td>30096</td>\n",
       "      <td>[TCGCG, CGCGT, GCGTG, CGTGC, GTGCC, TGCCG, GCC...</td>\n",
       "      <td>[0.2680618561736469, -0.021119162201327892, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>Class5</td>\n",
       "      <td>TACCACCTACGCTGACAATGGATGTTATTGTACCCGTTTCGAATTA...</td>\n",
       "      <td>10735</td>\n",
       "      <td>[TACCA, ACCAC, CCACC, CACCT, ACCTA, CCTAC, CTA...</td>\n",
       "      <td>[0.09989383920623382, -0.08351448598232104, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>Class6</td>\n",
       "      <td>TAGTTTTAGTAAGTTTGGTCCCATTCAATCACGTTCGGATGCGCTG...</td>\n",
       "      <td>2341</td>\n",
       "      <td>[TAGTT, AGTTT, GTTTT, TTTTA, TTTAG, TTAGT, TAG...</td>\n",
       "      <td>[0.1354878669723666, -0.08694451862251948, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>Class1</td>\n",
       "      <td>GCTGGGTAATTTTAGGTTGGTTGGCGATCGCGCCACTATCGCACCG...</td>\n",
       "      <td>29350</td>\n",
       "      <td>[GCTGG, CTGGG, TGGGT, GGGTA, GGTAA, GTAAT, TAA...</td>\n",
       "      <td>[0.16401321047208844, -0.08347763841540236, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>Class5</td>\n",
       "      <td>TACCACCTACGCTGACAATGGATGTTATTGTACCCGATTCGAATTA...</td>\n",
       "      <td>10735</td>\n",
       "      <td>[TACCA, ACCAC, CCACC, CACCT, ACCTA, CCTAC, CTA...</td>\n",
       "      <td>[0.12067560817271122, -0.07888817984440853, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>Class3</td>\n",
       "      <td>TATCGCACCGCGCTTTGATTGCCCTTTTCGCACACAAGCACGTGCG...</td>\n",
       "      <td>29782</td>\n",
       "      <td>[TATCG, ATCGC, TCGCA, CGCAC, GCACC, CACCG, ACC...</td>\n",
       "      <td>[0.21581861273456737, -0.046567836955902046, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1320 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Type                                           Sequence    len  \\\n",
       "0     Class5  TACCACCTACGCTGACAATGGATGTTATTGTACCCGATTCGAATTA...  10735   \n",
       "1     Class5  TGTTTATGTATCCGCCCATAAATAGCTTAGCGTTGACTACCGCTTG...  10737   \n",
       "2     Class3  TCAATATAGGCCACGGGCAACCCGTTGATATTTTGTGTGACGGTTG...  29409   \n",
       "3     Class6  TAGTTTTAGTAACGTTCCTCTCCGTTCTCAATTTATTCTTTTATTG...   2341   \n",
       "4     Class2  TCGCGTGCCGGGGCGACCGCGCCAGTATTGCCCATCCCCTTGATTG...  30096   \n",
       "...      ...                                                ...    ...   \n",
       "1315  Class5  TACCACCTACGCTGACAATGGATGTTATTGTACCCGTTTCGAATTA...  10735   \n",
       "1316  Class6  TAGTTTTAGTAAGTTTGGTCCCATTCAATCACGTTCGGATGCGCTG...   2341   \n",
       "1317  Class1  GCTGGGTAATTTTAGGTTGGTTGGCGATCGCGCCACTATCGCACCG...  29350   \n",
       "1318  Class5  TACCACCTACGCTGACAATGGATGTTATTGTACCCGATTCGAATTA...  10735   \n",
       "1319  Class3  TATCGCACCGCGCTTTGATTGCCCTTTTCGCACACAAGCACGTGCG...  29782   \n",
       "\n",
       "                                                 k-mers  \\\n",
       "0     [TACCA, ACCAC, CCACC, CACCT, ACCTA, CCTAC, CTA...   \n",
       "1     [TGTTT, GTTTA, TTTAT, TTATG, TATGT, ATGTA, TGT...   \n",
       "2     [TCAAT, CAATA, AATAT, ATATA, TATAG, ATAGG, TAG...   \n",
       "3     [TAGTT, AGTTT, GTTTT, TTTTA, TTTAG, TTAGT, TAG...   \n",
       "4     [TCGCG, CGCGT, GCGTG, CGTGC, GTGCC, TGCCG, GCC...   \n",
       "...                                                 ...   \n",
       "1315  [TACCA, ACCAC, CCACC, CACCT, ACCTA, CCTAC, CTA...   \n",
       "1316  [TAGTT, AGTTT, GTTTT, TTTTA, TTTAG, TTAGT, TAG...   \n",
       "1317  [GCTGG, CTGGG, TGGGT, GGGTA, GGTAA, GTAAT, TAA...   \n",
       "1318  [TACCA, ACCAC, CCACC, CACCT, ACCTA, CCTAC, CTA...   \n",
       "1319  [TATCG, ATCGC, TCGCA, CGCAC, GCACC, CACCG, ACC...   \n",
       "\n",
       "                                                    vec  \n",
       "0     [0.14347037438654303, -0.09826718607041093, -0...  \n",
       "1     [0.15608204759534353, -0.10743600239410199, -0...  \n",
       "2     [0.22348955288315472, -0.045752539952623295, 0...  \n",
       "3     [0.12861910830795006, -0.06960499866601161, -0...  \n",
       "4     [0.2680618561736469, -0.021119162201327892, 0....  \n",
       "...                                                 ...  \n",
       "1315  [0.09989383920623382, -0.08351448598232104, -0...  \n",
       "1316  [0.1354878669723666, -0.08694451862251948, -0....  \n",
       "1317  [0.16401321047208844, -0.08347763841540236, 0....  \n",
       "1318  [0.12067560817271122, -0.07888817984440853, -0...  \n",
       "1319  [0.21581861273456737, -0.046567836955902046, 0...  \n",
       "\n",
       "[1320 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_vec_model = DocToVec(dataset=df[\"k-mers\"].to_list())\n",
    "df[\"vec\"]= df[\"k-mers\"].apply(lambda x:word_to_vec_model.embed(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b9c102",
   "metadata": {},
   "source": [
    "در سلول زیر داده‌های ورودی که برای آموزش مورد نیاز هست  با لیبلشان از دیتافریم بیرون میکشیم و  به آرایه های نامپای تبدیل میکنیم "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29ba7333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1320,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y= df[\"Type\"].to_list()\n",
    "X = np.array(df[\"vec\"].to_list())\n",
    "\n",
    "# change to np\n",
    "le = preprocessing.LabelEncoder()\n",
    "Y =le.fit_transform(Y)\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e6ea74",
   "metadata": {},
   "source": [
    "داده های خود را به دو داده آموزش و ارزیابی تقسیم بندی میکنیم تا مدل بدست امده را ارزیابی کنیم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c9b6b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c047a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(884, 200)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0a5e7c",
   "metadata": {},
   "source": [
    "حال داده های ما برای مدل اماده شده اند شبکه عصبی ساده ای در نظر میگیریم  چون ورودی های وکتور های ۲۰۰ تایی هستند پس  \n",
    "\n",
    "input -> 200\n",
    "\n",
    "و دو لایه مخفی در نظر میگیریم و از تابع فعال سازی \n",
    "\n",
    "relu\n",
    "\n",
    "و لایه اخر را نیز   به طول ۶ در نظر میگیرییم زیرا ۶ کلاس بیشتر نداریم\n",
    "و از آپتیمایز آدام استفاده کرده ایم زیرا بج سایز را کم در نظر گرفته ایم ۳۲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82110939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-04 03:16:46.112613: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-04 03:16:46.112725: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model =Sequential()\n",
    "model.add(Input(shape=(200,)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef6f899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85b57d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-04 03:16:46.239489: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-07-04 03:16:46.391839: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 6ms/step - loss: 1.3806 - accuracy: 0.6324\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.6896 - accuracy: 0.8575\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.3032 - accuracy: 0.9977\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1414 - accuracy: 0.9977\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0755 - accuracy: 0.9977\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0385 - accuracy: 0.9989\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0234 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3128ce250>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train, batch_size=32 , epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15ccfcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 - 0s - loss: 0.0070 - accuracy: 1.0000 - 135ms/epoch - 10ms/step\n",
      "Test accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-04 03:16:48.088333: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,  Y_test, verbose=2)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d2b8dc",
   "metadata": {},
   "source": [
    "همانطور که دیدیم مدل ما روی داده های تستی که از تقسیم بندی به دست آمده بود به خوبی عمل کرده است\n",
    "حال از داده های دولوپ استفاده میکنیم تا مدل را ارزیابی کنیم\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad4a4919",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-04 03:16:50.142286: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "dev_df = pd.read_csv(\"./data/development_set.csv\")\n",
    "dev_df[\"k-mers\"] = dev_df[\"Sequence\"].apply(lambda x :build_kmers(x,5))\n",
    "dev_df['vec']=dev_df['k-mers'].apply(lambda x:word_to_vec_model.embed(x))\n",
    "dev__vecs = np.array(dev_df[\"vec\"].to_list())\n",
    "output= model.predict(dev__vecs)\n",
    "results = list(le.inverse_transform(np.argmax(output,axis=1)))\n",
    "dev_df[\"predicted\"]=pd.Series(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7c458e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_on_development_dataset= 100.0%\n"
     ]
    }
   ],
   "source": [
    "accuracy = sum(dev_df[\"Type\"]==dev_df[\"predicted\"])/len(dev_df)\n",
    "print(F\"accuracy_on_development_dataset= {accuracy*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeca8b0",
   "metadata": {},
   "source": [
    "باز هم مدل روی این داده ها خوب عمل کرده و دقت ۱۰۰ درصد را دارد\n",
    "حال به سراغ داده های تست میرویم تا آنهارا پیشبینی کنیم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c771ffa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TACTACCTACGCTGACAATGGATGTTATTGTACCCGATTCGAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TACTACCTACGCTGACAATGGATGTTATTGTACCCGATTCGAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCCTTTAACCCTCTGGCCGGGTAACTTGTTTGGTTGGTTGCCCGAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCTCCTAACCCCCTGGCTGGGTAATTTTAGGTTGGTTGGCGATCGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GTTTGGTCCCATTCAATCACGTTCGGATGCGCTGCACCGCCTTTTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>GTAATTTTAGGTTGGTTGGCGATCGCGCCACTATCGCACCGCGCTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>GTTTGGTTGGTTGCCCGATCGCGCCACTATCGCACCGCGCTTTGAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>ATCCCTTACATTCTAGCCAAGCTCGCGTGCCCGGGCGACCGCGCCA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>TACTACCTACGCTGACAATGGATGTTATTGTACCCGATTCGAATTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>GTAATTTTAGGTTGGTTGGCGATCGCGCCACTATCGCACCGCGCTT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sequence\n",
       "0    TACTACCTACGCTGACAATGGATGTTATTGTACCCGATTCGAATTA...\n",
       "1    TACTACCTACGCTGACAATGGATGTTATTGTACCCGATTCGAATTA...\n",
       "2    TCCTTTAACCCTCTGGCCGGGTAACTTGTTTGGTTGGTTGCCCGAT...\n",
       "3    TCTCCTAACCCCCTGGCTGGGTAATTTTAGGTTGGTTGGCGATCGC...\n",
       "4    GTTTGGTCCCATTCAATCACGTTCGGATGCGCTGCACCGCCTTTTA...\n",
       "..                                                 ...\n",
       "395  GTAATTTTAGGTTGGTTGGCGATCGCGCCACTATCGCACCGCGCTT...\n",
       "396  GTTTGGTTGGTTGCCCGATCGCGCCACTATCGCACCGCGCTTTGAT...\n",
       "397  ATCCCTTACATTCTAGCCAAGCTCGCGTGCCCGGGCGACCGCGCCA...\n",
       "398  TACTACCTACGCTGACAATGGATGTTATTGTACCCGATTCGAATTA...\n",
       "399  GTAATTTTAGGTTGGTTGGCGATCGCGCCACTATCGCACCGCGCTT...\n",
       "\n",
       "[400 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"./data/test_set.csv\")\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b16ab8e",
   "metadata": {},
   "source": [
    "داده های تست همانند داده های آموزش میخوانیم و همان عملیاتی را که روی داده های آمورش انجام دادیم را روی آن انجام میدهیم و سپس به مدل میدهیم و نتیجه را برمیگردانیم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e436c758",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"k-mers\"] = test_df[\"Sequence\"].apply(lambda x :build_kmers(x,5))\n",
    "test_df['vec']=test_df['k-mers'].apply(lambda x:word_to_vec_model.embed(x))\n",
    "test_vecs = np.array(test_df[\"vec\"].to_list())\n",
    "output= model.predict(test_vecs)\n",
    "results = list(le.inverse_transform(np.argmax(output,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb2d7ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Class5', 'Class5', 'Class3', 'Class1', 'Class6', 'Class1', 'Class6', 'Class3', 'Class4', 'Class1', 'Class4', 'Class3', 'Class2', 'Class4', 'Class4', 'Class3', 'Class6', 'Class3', 'Class3', 'Class3', 'Class4', 'Class1', 'Class5', 'Class6', 'Class1', 'Class5', 'Class3', 'Class3', 'Class3', 'Class3', 'Class1', 'Class3', 'Class6', 'Class1', 'Class6', 'Class1', 'Class3', 'Class5', 'Class5', 'Class6', 'Class5', 'Class4', 'Class5', 'Class5', 'Class3', 'Class6', 'Class4', 'Class5', 'Class1', 'Class2', 'Class4', 'Class3', 'Class4', 'Class3', 'Class3', 'Class6', 'Class1', 'Class6', 'Class5', 'Class3', 'Class1', 'Class3', 'Class3', 'Class3', 'Class3', 'Class6', 'Class4', 'Class5', 'Class6', 'Class6', 'Class6', 'Class3', 'Class2', 'Class6', 'Class1', 'Class1', 'Class4', 'Class6', 'Class6', 'Class2', 'Class5', 'Class4', 'Class1', 'Class1', 'Class3', 'Class5', 'Class6', 'Class4', 'Class3', 'Class5', 'Class3', 'Class1', 'Class1', 'Class6', 'Class5', 'Class3', 'Class5', 'Class1', 'Class4', 'Class1', 'Class3', 'Class3', 'Class2', 'Class1', 'Class3', 'Class4', 'Class3', 'Class3', 'Class3', 'Class3', 'Class3', 'Class1', 'Class4', 'Class1', 'Class4', 'Class4', 'Class3', 'Class3', 'Class3', 'Class4', 'Class6', 'Class1', 'Class6', 'Class4', 'Class5', 'Class3', 'Class6', 'Class2', 'Class1', 'Class3', 'Class3', 'Class6', 'Class5', 'Class2', 'Class2', 'Class3', 'Class2', 'Class1', 'Class3', 'Class3', 'Class5', 'Class1', 'Class6', 'Class1', 'Class2', 'Class2', 'Class1', 'Class3', 'Class1', 'Class1', 'Class6', 'Class6', 'Class2', 'Class6', 'Class3', 'Class5', 'Class5', 'Class3', 'Class6', 'Class3', 'Class1', 'Class2', 'Class4', 'Class4', 'Class3', 'Class3', 'Class5', 'Class4', 'Class1', 'Class1', 'Class2', 'Class3', 'Class6', 'Class1', 'Class3', 'Class2', 'Class6', 'Class4', 'Class5', 'Class6', 'Class5', 'Class6', 'Class5', 'Class5', 'Class6', 'Class3', 'Class3', 'Class3', 'Class6', 'Class4', 'Class6', 'Class3', 'Class3', 'Class6', 'Class6', 'Class6', 'Class1', 'Class1', 'Class5', 'Class1', 'Class1', 'Class3', 'Class3', 'Class1', 'Class1', 'Class1', 'Class5', 'Class3', 'Class2', 'Class2', 'Class1', 'Class1', 'Class1', 'Class1', 'Class3', 'Class6', 'Class3', 'Class3', 'Class4', 'Class5', 'Class6', 'Class4', 'Class1', 'Class4', 'Class3', 'Class4', 'Class6', 'Class5', 'Class4', 'Class6', 'Class5', 'Class5', 'Class6', 'Class6', 'Class4', 'Class5', 'Class3', 'Class6', 'Class6', 'Class3', 'Class1', 'Class1', 'Class4', 'Class4', 'Class4', 'Class5', 'Class1', 'Class2', 'Class6', 'Class1', 'Class6', 'Class3', 'Class2', 'Class2', 'Class1', 'Class2', 'Class3', 'Class6', 'Class6', 'Class5', 'Class1', 'Class3', 'Class6', 'Class1', 'Class3', 'Class3', 'Class1', 'Class1', 'Class5', 'Class4', 'Class1', 'Class3', 'Class1', 'Class2', 'Class1', 'Class1', 'Class3', 'Class3', 'Class3', 'Class6', 'Class1', 'Class6', 'Class4', 'Class1', 'Class3', 'Class4', 'Class3', 'Class3', 'Class4', 'Class3', 'Class1', 'Class3', 'Class6', 'Class6', 'Class2', 'Class1', 'Class6', 'Class2', 'Class1', 'Class6', 'Class6', 'Class1', 'Class4', 'Class1', 'Class6', 'Class5', 'Class6', 'Class3', 'Class4', 'Class2', 'Class4', 'Class3', 'Class1', 'Class6', 'Class5', 'Class5', 'Class2', 'Class3', 'Class5', 'Class4', 'Class5', 'Class1', 'Class3', 'Class3', 'Class4', 'Class1', 'Class1', 'Class1', 'Class1', 'Class2', 'Class1', 'Class5', 'Class2', 'Class3', 'Class3', 'Class4', 'Class2', 'Class5', 'Class1', 'Class5', 'Class4', 'Class1', 'Class1', 'Class3', 'Class3', 'Class2', 'Class5', 'Class4', 'Class4', 'Class3', 'Class2', 'Class5', 'Class1', 'Class2', 'Class1', 'Class2', 'Class1', 'Class2', 'Class2', 'Class3', 'Class5', 'Class6', 'Class1', 'Class6', 'Class3', 'Class1', 'Class6', 'Class4', 'Class1', 'Class1', 'Class1', 'Class2', 'Class3', 'Class5', 'Class6', 'Class3', 'Class1', 'Class1', 'Class4', 'Class2', 'Class1', 'Class6', 'Class3', 'Class6', 'Class3', 'Class4', 'Class2', 'Class6', 'Class6', 'Class3', 'Class3', 'Class2', 'Class2', 'Class6', 'Class3', 'Class1', 'Class3', 'Class2', 'Class5', 'Class1']\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad351da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311ed80b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensor_venv",
   "language": "python",
   "name": "tensor_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
